from cyexploit import ExploitCore as Exploit
import experiment_handling as eh
import numpy as np
import networkx as nx
import pandas as pd
import cPickle
import itertools as it

# The folder where to store the experiment's data
SAVE_PATH = "/home/barfuss/Downloads/ExploitExperiments/TauPhiReproduction/"
# The sample size
SAMPLE_SIZE = 16

# Setting up the parameter combinations to run
taus = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7]
phis = [0.0, 0.2, 0.4, 0.6, 0.8]
# phis = [0.0]

N, K, g, smax, gamma = [500], 20, [1], [1], [1]
link_density = [float(K)/float(N[0])]

PARAM_COMBS = list(it.product(taus, phis, N, link_density, smax, g, gamma))


# The model set up, run and save function
def RUN_FUNC(tau, phi, N, link_density, smax, g, gamma, filename):
    """
    Setting up the model with various parameters and determine what and how to
    save the outcome. This is done with a pickeld dictionary including the
    inital values, some parameters (for double checking) and the consensous
    state and time - if the model reached consensus.

    Parameters
    ----------
    tau : float
        the social update timescale
    phi : float
        the rewiring probability (between 0 and 1)
    N : int
        the number of agents/resources
    link_density : float
        the link density of the erdoes-renyi network
    g : float
        the (homogenous) growth rate of all resources
    gamma : float
        the (homogenous) rationality of all agents
    filename : string
        the filename where to pickle - passed from "experiment_handling"
        This needs to be the last parameter of the RUN_FUNC
    """
    MaxStocks = smax * np.ones(N)  # Homogenous capacities
    Stocks = np.random.rand(N) * MaxStocks  # Random inital stocks
    Strategies = np.random.randint(2, size=N)  # Random inital strategies
    GrowthRates = g * np.ones(N)  # Homogenous growth rates g
    Rationalities = gamma * np.ones(N)  # Homogenous rationalities gamma

    # Connected adjacnecy matrix
    net = nx.erdos_renyi_graph(N, link_density)
    while len(list(nx.connected_components(net))) > 1:
        print "Network has isolated components. Try again!"
        net = nx.erdos_renyi_graph(N, link_density)
    A = nx.adj_matrix(net).toarray()

    # Prepare storing inititals
    res = {}
    res["initials"] = pd.DataFrame({"MaxStocks": MaxStocks,
                                    "Stocks": Stocks,
                                    "Strategies": Strategies})
    # Prpare storing parameters
    res["parameters"] = pd.Series({"N": N,
                                   "link_density": link_density,
                                   "growth_rate": g,
                                   "rationality": gamma,
                                   "max_stock": smax,
                                   "rewiring_prob": phi,
                                   "update_timescale": tau})

    # Running the model
    m = Exploit(A, Strategies, Stocks, MaxStocks, GrowthRates,
                Rationalities, phi, tau)
    exit_status = m.run()

    if exit_status == 1:
        # Prepare storing consensus state
        res["consensus"] = pd.DataFrame({"Strategies": m.get_strategies(),
                                         "Stocks": m.get_stocks()})
        res["consensus_time"] = m.get_time()

    cPickle.dump(res, open(filename, "wb"))
    return exit_status


def compute():
    """
    Compute the model of the specified paramters
    """
    eh.compute(RUN_FUNC, PARAM_COMBS, SAMPLE_SIZE, SAVE_PATH)


INDEX = {0: "tau", 1: "phi"}
EVA = {"<<sus>>": (lambda fnames: np.mean([np.load(f)["consensus"]
                   ["Strategies"].mean() for f in fnames])),
       "std(<sus>)": (lambda fnames: np.std([np.load(f)["consensus"]
                      ["Strategies"].mean() for f in fnames])),
       "<cons_time>": lambda fnames: np.mean([np.load(f)["consensus_time"]
                                              for f in fnames])}


def resave(sample_size=None):
    NAME = "TauPhiReproduction_SampleSize" + str(sample_size)\
        + ".pkl"
    badmisskey = "consensus"
    eh.resave_data(SAVE_PATH, PARAM_COMBS, INDEX, EVA, NAME, badmisskey,
                   sample_size)
