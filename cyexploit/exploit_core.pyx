# cython: profile=True

import numpy as np
from scipy.sparse.csgraph import connected_components

cimport cython
from cpython cimport bool
from libc.math cimport exp, tanh

import numpy as np
cimport numpy as np

INTTYPE = np.int
FLOATTYPE = np.float
ctypedef np.int_t INTTYPE_t
ctypedef np.float_t FLOATTYPE_t

cdef extern from "stdlib.h":
    double drand48()

cdef class ExploitCore(object):
    """
    The Exploit model is an agent based model, conceptualizing planetary
    social-ecological coevolution. Each of the N agents harvests her individual
    resource according to either a sustainble or non-sustainble strategy. These
    strategies get updated via a opinion foramtion process covering two key
    schemes of social interaction: imitation and homophily.

    Parameters
    ----------
    adjacency_matrix : np.array[N,N] of dtype int
        The initial interaction matrix of the agents
    strategies : np.array[N] of dtype int
        The inital strategies [1 denotes sus.; 0 denotes non-sus]
    stocks : np.array[N] of dtype float
        The inital stocks (for each agent i: stock[i] needs to be below
        max_stocks[i])
    max_stocks : np.array[N] of dtype float
        Maximum stocks (also called Capacities) of the logistic resource
    growth_rates : np.array[N] of dtype float
        Growth rates of the logistic resource
    rationalities : np.array[N] of dtype float
        Rationality parameter of the agents concerning the social imitation
    rewiring_prob : float
        The rewiring probability (needs to be between 0 and 1)
    update_timescale : float
        The update timescale determining the waiting times for the updates


    Example
    -------
    >>> import numpy as np
    >>> import networkx as nx
    >>>
    >>> N = 100                           # Number of agents
    >>> p = 0.35                          # link density
    >>>                                   # Adjaceny matrix
    >>> A = nx.adj_matrix(nx.erdos_renyi_graph(N,p)).toarray()
    >>> S = np.random.randint(2, size=N)  # Agent's Strategies
    >>> s = np.ones(N)                    # Agent's Stocks
    >>> smax = np.ones(N)                 # Agent's Maximum Stocks (Capacities)
    >>> g = np.ones(N)                    # Agent's Growth Rates
    >>> r = np.ones(N)                    # Agent's Rationalities
    >>> phi = 0.0                         # Rewiring probability
    >>> tau = 1.0                         # Update timescale
    >>>
    >>> m = ExploitCore(A, S, s, smax, g, r, phi, tau)
    >>> m.run()
    >>>
    >>> print "Consensus?:              " + str(m.get_consensus())
    >>> print "Fraction of sus. agents: " + str(m.get_strategies().mean())
    >>> print "Model Time:              " + str(m.get_time())

    """

    cdef:
        np.ndarray adjacency_matrix
        unsigned int N

        np.ndarray a_Strategy
        np.ndarray a_Stock
        np.ndarray a_MaxStock
        np.ndarray a_GrowthRate
        np.ndarray a_Rationality
        np.ndarray a_UpdateTime

        double rewiring_prob
        double update_timescale

        double time
        bool consensus

    def __init__(self,
                 np.ndarray[INTTYPE_t, ndim=2] adjacency_matrix,
                 np.ndarray[INTTYPE_t, ndim=1] strategies,
                 np.ndarray[FLOATTYPE_t, ndim=1] stocks,
                 np.ndarray[FLOATTYPE_t, ndim=1] max_stocks,
                 np.ndarray[FLOATTYPE_t, ndim=1] growth_rates,
                 np.ndarray[FLOATTYPE_t, ndim=1] rationalities,
                 double rewiring_prob,
                 double update_timescale):

        # Interaction graph
        self.adjacency_matrix = adjacency_matrix

        # Storing the agent's data with prefix a_
        self.a_Strategy = strategies
        self.a_Stock = stocks
        self.a_MaxStock = max_stocks
        self.a_GrowthRate = growth_rates
        self.a_Rationality = rationalities

        # parameters
        self.rewiring_prob = rewiring_prob
        self.update_timescale = update_timescale

        # derivations
        self.N = self.adjacency_matrix.shape[0]
        self.a_UpdateTime =\
            np.random.exponential(self.update_timescale, self.N)

        self.time = 0
        self._check_for_consensus()

    def __str__(self):
        return "Instance of the Exploit Model (Core) of size %i" % self.N

    def get_consensus(self):
        """
        Return the True if the model is in the consensus state,
        otherwise False
        """
        return self.consensus

    def get_adjacency(self):
        """
        Return the current adjacency matrix.
        """
        return self.adjacency_matrix

    def get_strategies(self):
        """
        Return the current strategies of the agents.
        """
        return self.a_Strategy

    def get_stocks(self):
        """
        Return the current stocks of the agents.
        """
        return self.a_Stock

    def get_time(self):
        """
        Return the current model time.
        """
        return self.time

    def run(self, int steps=1000000000):
        """
        Running the model either for a defined number of update steps or into
        the consensus state. Thus, perfoming one update means setting
        steps = 1.

        Parameter
        ---------
        steps : int
            The number of steps to be performed [Default: 10000000]. If the
            model gets into the consensus state before the total number of
            steps could be perfomed, the model run ends immediatly.

        Return
        ------
        exit_status : int
            if exit_status ==  1: End with consensus
            if exit_status ==  0: End without consensus
            if exit_status == -1: No update candidates could be found and no
                consensus detacted (BAD)
        """
        cdef:
            int agent, neighb
            double update_time
            np.ndarray[INTTYPE_t, ndim=1] neighbors
            np.ndarray[FLOATTYPE_t, ndim=1] harvest

        for i in xrange(steps):
            agent, neighb, neighbors, update_time = self._update_candiadates()
            if self.consensus: return 1  # consensus
            if agent == -1: return -1    # no update canditates found (BAD)
            harvest = self._integrate_forward(update_time)
            self._perform_social_update(agent, neighb, neighbors, harvest)
        return 0                         # no consensus

    cdef bool _check_for_consensus(self):
        """
        Check for consensus.

        Returns
        -------
        consensus : bool
            True if model is into consensus state, otherwise False
        """
        cc = connected_components(self.adjacency_matrix, directed=False)[1]
        self.consensus = all(len(np.unique(self.a_Strategy[c])) == 1
                             for c in ((cc == i).nonzero()[0]
                             for i in np.unique(cc)))
        return self.consensus

    cdef _update_candiadates(self):
        """
        Find an agent and one of its neighbors that are suitable for an update.

        Returns
        -------
        object : (agent, neighbor, neighbors, update_time)
            agent : int
                the index number of the update agent OR -1 if no update
                candidates could be found and no consensus is detected
            neighbor : int
                the index of one of its neighbors
            neighbors : np.array of type int
                all neighbors of agent (needed for the social update)
            update_time : double
                the model time of the update (needed for the stock integration)
        """
        cdef:
            int i, agent, neighb=self.N, N=self.N
                # neighb == N means update candidate not found
            double update_time=0.0, update_timescale=self.update_timescale
            np.ndarray[FLOATTYPE_t, ndim=1] a_UpdateTime = self.a_UpdateTime
            np.ndarray[INTTYPE_t, ndim=1] a_Strategy = self.a_Strategy
            np.ndarray[INTTYPE_t, ndim=2] adj_mat = self.adjacency_matrix
            np.ndarray[INTTYPE_t, ndim=1] neighbors

        # Needs to return alwas an int, int, np.ndarray, double
        i = 0
        while i < 100*N:
            agent = a_UpdateTime.argmin()
            update_time = a_UpdateTime[agent]
            a_UpdateTime[agent] += np.random.exponential(update_timescale)
            neighbors = adj_mat[agent].nonzero()[0]

            if len(neighbors) > 0:
                neighb = np.random.choice(neighbors)
                if (a_Strategy[neighb] == a_Strategy[agent]):
                    # Update candidates NOT found
                    neighb = N

            if neighb < N:  # Update candidates found
                break
            else:  # No neighb found
                i += 1
                if i >= N:  # more than N agents wer unsuitable
                    if self._check_for_consensus():
                        # return because of consensus
                        break
        if i >= 100*N:  # no update candidates found and no consensus
            agent = -1

        return agent, neighb, neighbors, update_time

    cdef np.ndarray _integrate_forward(self, double update_time):
        """
        Integrate the stocks forward to the update_time.

        Parameters
        ----------
        update_time : double
            The model time where the the social update is performed

        Returns
        -------
        harvests : np.array[N] of type float
            The current harvests for each agent (needed for the social update)
        """
        cdef:
            unsigned int i
            double dt = update_time - self.time
            double s0i, gi, Ei, smaxi, s1i, b, gs0
            np.ndarray[FLOATTYPE_t, ndim=1] s0 = self.a_Stock
            np.ndarray[FLOATTYPE_t, ndim=1] smax = self.a_MaxStock
            np.ndarray[FLOATTYPE_t, ndim=1] g = self.a_GrowthRate
            np.ndarray[INTTYPE_t, ndim=1] S = self.a_Strategy
            np.ndarray[FLOATTYPE_t, ndim=1] harvest = np.zeros(self.N)
            np.ndarray[FLOATTYPE_t, ndim=1] s1 = np.zeros(self.N)

        # Turns out to be faster than the vectorized computation
        for i in xrange(self.N):
            s0i = s0[i]
            smaxi = smax[i]
            gi = g[i]
            Ei = g[i] * 0.5 * (3-2*S[i])
            b = gi - Ei
            gs0 = gi * s0i
            s1i = s0i*smaxi*b / ((smaxi*b-gs0)*exp(-b * dt) + gs0)
            harvest[i] = Ei * s1i
            s1[i] = s1i

        self.time += dt    # Update the model time
        self.a_Stock = s1  # Update the stock
        return harvest

    cdef void _perform_social_update(
        self, int agent, int neighb, np.ndarray[INTTYPE_t, ndim = 1] neighbors,
        np.ndarray[FLOATTYPE_t, ndim = 1] harvests):
        """
        Perform a social update.

        Parameters
        ----------
        agent : int
            The index of the current update agent
        neighb : int
            The index of its update neighbor
        neighbors : np.array of type int
            All of the neighbors of the update agent
        harvests : np.array[N] of type float
            The current harvest of all the agents
        """
        cdef:
            int j, new_nb
            double dH, rewiring_prob=self.rewiring_prob
            np.ndarray[INTTYPE_t, ndim=1] same_unconnected =\
                np.zeros(self.N, dtype=int)
            np.ndarray[INTTYPE_t, ndim=1] S = self.a_Strategy
            np.ndarray[INTTYPE_t, ndim=2] A = self.adjacency_matrix

        if (rewiring_prob == 1 or
            (rewiring_prob != 0 and
             drand48() < rewiring_prob)):
            # rewire
            for j in xrange(self.N):
                if (S[j] == S[agent] and j not in neighbors and j != agent):
                    same_unconnected[j] = 1
            same_unconnected = same_unconnected.nonzero()[0]
            if len(same_unconnected) > 0:
                new_nb = np.random.choice(same_unconnected)
                A[agent, neighb] = A[neighb, agent] = 0
                A[agent, new_nb] = A[new_nb, agent] = 1

        else:
            # switch effort
            dH = harvests[neighb] - harvests[agent]
            if drand48() < 0.5 * (tanh(self.a_Rationality[agent]*dH) + 1):
                self.a_Strategy[agent] = self.a_Strategy[neighb]
