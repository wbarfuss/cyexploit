"""
In this experiment the stock's capacities are normally distributed
"""
from cyexploit import ExploitCore as Exploit
from modelingframework import experiment_handling as eh
import numpy as np
import networkx as nx
import pandas as pd
import cPickle
import itertools as it
import sys

# Specifiy the SAVE PATH ------------------------------------------------------
# The folder where to store the experiment's data

# For use on the cluster
SAVE_PATH = "/home/barfuss/ExploitExperiments/NormalCapacities/"

# For local access to the cluster's raw data
# SAVE_PATH = "/home/barfuss/mnt/PIKCluster/" +\
#             "ExploitExperiments/NormalCapacities/"

# For local testing
# SAVE_PATH = "/home/barfuss/Downloads/ExploitExperiments/NormalCapacities/"
# -----------------------------------------------------------------------------


# The model set up, run and save function -------------------------------------
def RUN_FUNC(tau, phi, sigma, mu, N, link_density, g, gamma, filename):
    """
    Setting up the model with various parameters and determine what and how to
    save the outcome. This is done with a pickeld dictionary including the
    inital values, some parameters (for double checking) and the consensous
    state and time - if the model reached consensus.

    Parameters
    ----------
    tau : float
        the social update timescale
    phi : float
        the rewiring probability (between 0 and 1)
    sigma : float
        the standard deviation of the normal distribution for the capacities
    mu : float
        the mean of the normal distribution for the capacities
    N : int
        the number of agents/resources
    link_density : float
        the link density of the erdoes-renyi network
    g : float
        the (homogenous) growth rate of all resources
    gamma : float
        the (homogenous) rationality of all agents
    filename : string
        the filename where to pickle - passed from "experiment_handling"
        This needs to be the last parameter of the RUN_FUNC
    """
    MaxStocks = np.abs(np.random.normal(mu, sigma, size=N))  # normal
    Stocks = np.random.rand(N) * MaxStocks  # Random inital stocks
    Strategies = np.random.randint(2, size=N)  # Random inital strategies
    GrowthRates = g * np.ones(N)  # Homogenous growth rates g
    Rationalities = gamma * np.ones(N)  # Homogenous rationalities gamma

    # Connected adjacnecy matrix
    net = nx.erdos_renyi_graph(N, link_density)
    while len(list(nx.connected_components(net))) > 1:
        print "Network has isolated components. Try again!"
        net = nx.erdos_renyi_graph(N, link_density)
    A = nx.adj_matrix(net).toarray()

    # Prepare storing inititals
    res = {}
    res["initials"] = pd.DataFrame({"MaxStocks": MaxStocks,
                                    "Stocks": Stocks,
                                    "Strategies": Strategies})
    # Prpare storing parameters
    res["parameters"] = pd.Series({"N": N,
                                   "link_density": link_density,
                                   "growth_rate": g,
                                   "rationality": gamma,
                                   "mu_lognorm": mu,
                                   "sigma_lognorm": sigma,
                                   "rewiring_prob": phi,
                                   "update_timescale": tau})

    # Running the model
    m = Exploit(A, Strategies, Stocks, MaxStocks, GrowthRates,
                Rationalities, phi, tau)
    exit_status = m.run()

    if exit_status == 1:
        # Prepare storing consensus state
        res["consensus"] = pd.DataFrame({"Strategies": m.get_strategies(),
                                         "Stocks": m.get_stocks()})
        res["consensus_time"] = m.get_time()

    cPickle.dump(res, open(filename, "wb"))
    return exit_status
# -----------------------------------------------------------------------------


def compute():
    """
    Compute the model of the specified paramters
    """
    eh.compute(RUN_FUNC, PARAM_COMBS, SAMPLE_SIZE, SAVE_PATH,
               skipbadruns=True)


def resave(sample_size=None):
    EVA = {"<<sus>>": lambda fnames: np.mean([np.load(f)["consensus"]
           ["Strategies"].mean() for f in fnames]),
           "<cons_time>": lambda fnames: np.mean([np.load(f)["consensus_time"]
                                                 for f in fnames])}
    eh.resave_data(SAVE_PATH, PARAM_COMBS, INDEX, EVA, NAME, sample_size)

# Getting the subexperiment from the command line -----------------------------
if len(sys.argv) > 1:  # at least on other than the filename.py is given
    sub_experiment = int(sys.argv[1])
else:  # if not: use default
    sub_experiment = 0
# ----------------------------------------------------------------------------

# =============================================================================
#   Experiment 1.1 - sigma vs. tau
# =============================================================================
if sub_experiment == 0:
    # Setting up the parameter combinations to run
    taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,
            1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]
    phis = [0.0]
    sigmas = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45,
              0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]

    mu, N, K, g, gamma = [1], [500], 20, [1], [1]
    link_density = [float(K)/float(N[0])]

    PARAM_COMBS = list(it.product(taus, phis, sigmas, mu, N, link_density, g,
                                  gamma))
    NAME = "TauSigmaN_SampleSizeMax.pkl"
    INDEX = {0: "tau", 2: "sigma"}

    SAMPLE_SIZE = 200
    compute()
    # resave()

# =============================================================================
#   Experiment 1.2 - sigma vs. phi
# =============================================================================
if sub_experiment == 1:
    # Setting up the parameter combinations to run
    taus = [0.5]
    phis = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4,
            0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]
    sigmas = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45,
              0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]

    mu, N, K, g, gamma = [1], [500], 20, [1], [1]
    link_density = [float(K)/float(N[0])]

    PARAM_COMBS = list(it.product(taus, phis, sigmas, mu, N, link_density, g,
                                  gamma))
    NAME = "PhiSigmaN_SampleSizeMax.pkl"
    INDEX = {1: "phi", 2: "sigma"}

    SAMPLE_SIZE = 150
    compute()
